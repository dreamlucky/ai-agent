services:
  ai-agent:
    build: .
    container_name: ai-agent
    ports:
      - "11435:5000"  # Maps proxy to host
    volumes:
      - /mnt/ai/data:/data
      - /mnt/ai/tools:/tools
      - /mnt/ai/prompts:/prompts
    environment:
      - OLLAMA_BACKEND=http://192.168.1.8:11434
    restart: unless-stopped

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    ports:
      - "8080:8080"
    depends_on:
      - ai-agent
    environment:
      - OLLAMA_API_BASE_URL=http://ai-agent:5000
    volumes:
      - /mnt/ai/openwebui:/app/backend/data
    restart: unless-stopped
